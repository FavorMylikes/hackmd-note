---
layout: single
title:  "VAE"
date:   "2023-9-11 13:45:49 +0800"
categories: AI
header:
  teaser: https://raw.githubusercontent.com/FavorMylikes/hackmd-note/img/img20230911134758.png
---


- AutoEncoder

<img src="https://raw.githubusercontent.com/FavorMylikes/hackmd-note/img/img20230911134751.png" alt="20230911134751"/>

- VAE

<img src="https://raw.githubusercontent.com/FavorMylikes/hackmd-note/img/img20230911134758.png" alt="20230911134758"/>

## 训练结构

<img src="https://raw.githubusercontent.com/FavorMylikes/hackmd-note/img/img20230911140823.png" alt="20230911140823"/>

### Reference

- [json007.gitbook.io](https://json007.gitbook.io/deeplearning/auto_encoder/variational_autoencoder)
  - 公式简洁，可能看不懂
  - 含代码，模型结构清晰
- [从零推导：变分自编码器（VAE） - Alex的文章 - 知乎](https://zhuanlan.zhihu.com/p/249296925)
  - 含有公式推导，比较清晰，以及对ELBO(Evidence Lower Bound)的理解比较到位
- [机器学习方法—优雅的模型（一）：变分自编码器（VAE） - 苗思奇的文章 - 知乎](https://zhuanlan.zhihu.com/p/348498294)
  - 含有公式推导，写的相对全面
- [c-harlin.github.io 理解VAE](https://c-harlin.github.io/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2019/09/11/VAE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0.html)
  - 从直观感受上理解VAE，有图
- [VAE、GAN 这种生成模型和 transformer 有什么区别？ - 知乎用户的回答 - 知乎](https://www.zhihu.com/question/558574918/answer/2711404815)
- [概论生成网络(GAN/VAE/Flow/Diffusion) - ZhouBH的文章 - 知乎](https://zhuanlan.zhihu.com/p/577974910)
  - 四种生成模型
- [通俗形象地分析比较生成模型（GAN/VAE/Flow/Diffusion/AR） - 谭旭的文章 - 知乎](https://zhuanlan.zhihu.com/p/591881660)

