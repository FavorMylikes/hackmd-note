<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.0">Jekyll</generator><link href="https://ucas.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://ucas.io/" rel="alternate" type="text/html" /><updated>2021-08-17T23:27:35+08:00</updated><id>https://ucas.io/feed.xml</id><title type="html">Notes B</title><subtitle>A place for notes on various topics.</subtitle><author><name>麦丽素</name></author><entry><title type="html">Convert Camera Parameters [usage of ContextCapture Master]</title><link href="https://ucas.io/3d/Camera-parameters-convert/" rel="alternate" type="text/html" title="Convert Camera Parameters [usage of ContextCapture Master]" /><published>2021-08-16T19:06:13+08:00</published><updated>2021-08-16T19:06:13+08:00</updated><id>https://ucas.io/3d/Camera-parameters-convert</id><content type="html" xml:base="https://ucas.io/3d/Camera-parameters-convert/">&lt;h2 id=&quot;convert-parameters&quot;&gt;Convert parameters&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;拿到&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;空三&lt;/code&gt;的参数文件，发现是&lt;strong&gt;Smart3D(soarscape.com)&lt;/strong&gt;的软件导出的，尝试下载，发现需要申请&lt;/li&gt;
  &lt;li&gt;根据关键字查找，找到&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ContextCapture Master&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;下载安装&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;model-generate&quot;&gt;Model generate&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Add photos&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/FavorMylikes/hackmd-note/img/img20210816192250.png&quot; alt=&quot;20210816192250&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;click submit aerotriangulation at general tab.
    &lt;ul&gt;
      &lt;li&gt;start &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ContextCapture Engine&lt;/code&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/FavorMylikes/hackmd-note/img/img20210816193823.png&quot; alt=&quot;20210816193823&quot; /&gt;&lt;/li&gt;
      &lt;li&gt;wait job complish&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Reconstruction&amp;gt;new Reconstruction&lt;/li&gt;
  &lt;li&gt;click &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;submit new production&lt;/code&gt;
    &lt;ul&gt;
      &lt;li&gt;wait for job complish&lt;/li&gt;
      &lt;li&gt;check production &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;3D view&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/FavorMylikes/hackmd-note/img/img20210816194645.png&quot; alt=&quot;20210816194645&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;output&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-console highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;go&quot;&gt; Model
├── Model.mtl
├── Model.obj
├── Model_0.jpg
├── Model_1.jpg
├── Model_2.jpg
└── Model_3.jpg
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;优点&quot;&gt;优点&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;纹理贴图压缩, 避免占用无效面积&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/FavorMylikes/hackmd-note/img/img20210816200325.png&quot; alt=&quot;20210816200325&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;非矩形纹理&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/FavorMylikes/hackmd-note/img/img20210816200429.png&quot; alt=&quot;20210816200429&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/FavorMylikes/hackmd-note/img/img20210816200450.png&quot; alt=&quot;20210816200450&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;图片畸变处理， 直接在贴图中使用Undistort的图片&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/FavorMylikes/hackmd-note/img/img20210816200728.png&quot; alt=&quot;20210816200728&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;缺点&quot;&gt;缺点&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;阴影被识别为特征点&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/FavorMylikes/hackmd-note/img/img20210816201323.png&quot; alt=&quot;20210816201323&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;纹理畸变过度&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/FavorMylikes/hackmd-note/img/img20210816201525.png&quot; alt=&quot;20210816201525&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;code&quot;&gt;Code&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://ucas/jupyter/lab/tree/3d/cameras/comera_convert.ipynb&quot;&gt;comera_convert&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;转换公式，参考&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Context capture master&lt;/code&gt;， &lt;a href=&quot;https://docs.bentley.com/LiveContent/web/ContextCapture%20Help-v10/en/GUID-2D452A8A-A4FE-450D-A0CA-9336DCF1238A.html&quot;&gt;文档&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;xml&lt;/code&gt;&lt;a href=&quot;https://docs.bentley.com/LiveContent/web/ContextCapture%20Help-v10/en/GUID-59E6CC36-F349-4DE0-A563-FFC47296A624.html&quot;&gt;文件含义&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/FavorMylikes/hackmd-note/img/img20210816202517.png&quot; alt=&quot;20210816202517&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;reference&quot;&gt;Reference&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/fb_help/article/details/84142580&quot;&gt;PhotoScan与smart3d的Omega,phi,kappa和R - fb_help[CSDN]&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/94244568&quot;&gt;相机标定之张正友标定法数学原理详解（含python源码） - 1335的文章 - 知乎&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/35287729&quot;&gt;相机模型&amp;amp;相机标定 - WwPpCc的文章 - 知乎&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>麦丽素</name></author><category term="3d" /><summary type="html">Convert parameters</summary></entry><entry><title type="html">Reading Texure paper</title><link href="https://ucas.io/3d/Reading-Texture-paper/" rel="alternate" type="text/html" title="Reading Texure paper" /><published>2021-08-16T14:55:52+08:00</published><updated>2021-08-16T14:55:52+08:00</updated><id>https://ucas.io/3d/Reading-Texture-paper</id><content type="html" xml:base="https://ucas.io/3d/Reading-Texture-paper/">&lt;h2 id=&quot;reconstructing-textured-meshes-from-multiple-rangergb-maps&quot;&gt;Reconstructing textured meshes from multiple range+rgb maps&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;ISTI-CNR&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;summary&quot;&gt;summary&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Minimizing redundancy and optimizing the color attribute represendtation&lt;/li&gt;
  &lt;li&gt;Eliminate most of the color difference or discontinuity which exist in input images
    &lt;ul&gt;
      &lt;li&gt;cross-correlation&lt;/li&gt;
      &lt;li&gt;interpolation&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;work-flow&quot;&gt;Work flow&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;visibility calculation
    &lt;ul&gt;
      &lt;li&gt;get a set of valid cameras/images for the face
        &lt;ul&gt;
          &lt;li&gt;ray-tracing calculation[耗时]&lt;/li&gt;
          &lt;li&gt;hardware-accelerated OpenGL
            &lt;ul&gt;
              &lt;li&gt;每个面一个颜色，用OpenGL直接渲染，选择相机能看到的颜色作为可观测颜色&lt;/li&gt;
              &lt;li&gt;但如果多个面都投影到同一个像素的话，太小的面就会被判定为不可见&lt;/li&gt;
              &lt;li&gt;优化
                &lt;ul&gt;
                  &lt;li&gt;通过迭代，每次迭代哪些尚未观测到的面&lt;/li&gt;
                  &lt;li&gt;随机抖动相机，或微调景深z-index，使得小面被观测到&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;patches generation
    &lt;ul&gt;
      &lt;li&gt;reduce the number of patch&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;sub-texture packing
    &lt;ul&gt;
      &lt;li&gt;locally-optimum greedy process&lt;/li&gt;
      &lt;li&gt;continuous texture but generally presents insufficient color continuity&lt;/li&gt;
      &lt;li&gt;&lt;img src=&quot;https://raw.githubusercontent.com/FavorMylikes/hackmd-note/img/img20210817225945.png&quot; alt=&quot;20210817225945&quot; /&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;imporving color matching and continuity
    &lt;ul&gt;
      &lt;li&gt;difference of color[iterate on vertices]
        &lt;ul&gt;
          &lt;li&gt;面$f$点$v$，$image_1\to patch_1$ has color $c_1$&lt;/li&gt;
          &lt;li&gt;$image_2\to patch_2$ has color $c_2$&lt;/li&gt;
          &lt;li&gt;$\bar image_{1,2}-c_1$意味着，$patch_1$到$patch_2$需要改变的颜色&lt;/li&gt;
          &lt;li&gt;&lt;img src=&quot;https://raw.githubusercontent.com/FavorMylikes/hackmd-note/img/img20210817230948.png&quot; alt=&quot;20210817230948&quot; /&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;pull-push interpolation method&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;state-of-the-art&quot;&gt;state of the art&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;texture mapping
    &lt;ul&gt;
      &lt;li&gt;image registration
        &lt;ul&gt;
          &lt;li&gt;point pair[点对]&lt;/li&gt;
          &lt;li&gt;integrate geometric- and image-based alignment[几何对齐]&lt;/li&gt;
          &lt;li&gt;silhouette-based registration[轮廓匹配]&lt;/li&gt;
          &lt;li&gt;&lt;strong&gt;Tsai algorithm&lt;/strong&gt;啥玩意&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;texture image is reconstructed from input image
        &lt;ul&gt;
          &lt;li&gt;map to mesh, sample color with &lt;strong&gt;non-redundant manner and optimizing&lt;/strong&gt;&lt;/li&gt;
          &lt;li&gt;weight blend&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;texture-for-9-9-file&quot;&gt;Texture for 9-9 file&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/FavorMylikes/hackmd-note/img/img20210817164050.png&quot; alt=&quot;20210817164050&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/FavorMylikes/hackmd-note/img/img20210817192738.png&quot; alt=&quot;20210817192738&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/FavorMylikes/hackmd-note/img/imga409b4eb5add76d66a1a713df1e5114.png&quot; alt=&quot;a409b4eb5add76d66a1a713df1e5114&quot; /&gt;&lt;/p&gt;</content><author><name>麦丽素</name></author><category term="3d" /><summary type="html">Reconstructing textured meshes from multiple range+rgb maps</summary></entry><entry><title type="html">PID and laplace transform</title><link href="https://ucas.io/zhihu/PID-and-laplace-transform/" rel="alternate" type="text/html" title="PID and laplace transform" /><published>2021-08-14T23:00:46+08:00</published><updated>2021-08-14T23:00:46+08:00</updated><id>https://ucas.io/zhihu/PID-and-laplace-transform</id><content type="html" xml:base="https://ucas.io/zhihu/PID-and-laplace-transform/">&lt;h2 id=&quot;pid-contorl&quot;&gt;PID Contorl&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;最常见的形式&lt;/li&gt;
  &lt;li&gt;$u(t)=K_pe(t)+K_i\int_0^te(\tau)d\tau+K_d\frac{d}{dt}e(t)$&lt;/li&gt;
  &lt;li&gt;其中
    &lt;ul&gt;
      &lt;li&gt;$K_p$为比例(proportional)增益&lt;/li&gt;
      &lt;li&gt;$K_i$为积分(integral)增益&lt;/li&gt;
      &lt;li&gt;$K_d$为微分(derivative)增益&lt;/li&gt;
      &lt;li&gt;$e=SP-PV$为误差，设定值(setpoint)$SP$与过程值(process variable)$PV$的差&lt;/li&gt;
      &lt;li&gt;$t$为时间&lt;/li&gt;
      &lt;li&gt;$\tau$积分变数，因为是历史状态的积分，因此要与$t$区分开来&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;比较常见的解释和应用&quot;&gt;比较常见的解释和应用&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;通过控制&lt;strong&gt;水箱&lt;/strong&gt;的流入速度，使得水箱内的高度或体积保持不变的一种过程&lt;/li&gt;
  &lt;li&gt;汽车定速巡航，遇到上坡如何设计动力&lt;/li&gt;
  &lt;li&gt;无人机的悬停和应激相应(推一下回到原来的位置，或者前往目标点)&lt;/li&gt;
  &lt;li&gt;解决电路问题&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;pid&quot;&gt;PID&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;通常学习PID控制时，往往不太懂得3个变量的实际作用，又有计算机作为辅助进行模拟，那么就会导致盲目调参，而书中提到的调参方法又只讲参数含义，将调参性质描述一遍，这样完全不得法门，最后只能得到一个差不多的结果&lt;/li&gt;
  &lt;li&gt;历史上
    &lt;ul&gt;
      &lt;li&gt;惠更斯17世纪改造了风车，使得磨盘转速和磨盘间隙可以根据谷物数量变化
        &lt;ul&gt;
          &lt;li&gt;Power From the Wind , Cambridge University Press&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;瓦特使用圆锥摆以解决蒸汽机的速度输出
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;https://web.archive.org/web/20160809050823/http://ieeecss.org/CSM/library/1996/june1996/02-HistoryofAutoCtrl.pdf&quot;&gt;History of AutoCtrl&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;1868年，为了更好的保持鱼雷的深度，引入了微分控制&lt;/li&gt;
      &lt;li&gt;直到1922年，才有了完整的3项控制率&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;因此，大多数书籍往往会根据每项变量引入时发挥的作用加以解释，但是又与纯PI控制，PD控制，甚至单纯的P控制应用相违背，除了硬件或成本上的限制，更需要思考的是，每一项为整个系统的稳定性到底提供了多大的好处&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;pid调参&quot;&gt;PID调参&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;为了获得更好的参数，有如下几种方法
    &lt;ul&gt;
      &lt;li&gt;手动&lt;/li&gt;
      &lt;li&gt;Ziegler–Nichols[齐格勒－尼科尔斯方法]
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Ziegler%E2%80%93Nichols_method&quot;&gt;Ziegler–Nichols_method - Wikipedia&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;https://www.bilibili.com/s/video/BV1ay4y117Bj&quot;&gt;使用Z-N方法调节气压 - Bilibili&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;将ID项置0，调节P使得达到恒定震荡，再根据震荡周期和震荡值计算PID参数&lt;/li&gt;
          &lt;li&gt;&lt;strong&gt;注意&lt;/strong&gt;，想要在P控制下得到稳定震荡，要有超调现象，如果通过计算机模拟，而时间单位又很小，那么无论用多大的$K_P$你都看不到超调现象，可以理解为，系统刚刚输入一点点就被感知到了，而上面视频里从气流输入到输出存在一定的延迟，因此可以使用该方法&lt;/li&gt;
          &lt;li&gt;反馈较慢
            &lt;ul&gt;
              &lt;li&gt;&lt;img src=&quot;https://raw.githubusercontent.com/FavorMylikes/hackmd-note/img/img20210816231759.png&quot; alt=&quot;20210816231759&quot; /&gt;&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;快速反馈
            &lt;ul&gt;
              &lt;li&gt;两处代码只更改了延迟&lt;/li&gt;
              &lt;li&gt;&lt;img src=&quot;https://raw.githubusercontent.com/FavorMylikes/hackmd-note/img/img20210816231835.png&quot; alt=&quot;20210816231835&quot; /&gt;&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;机器学习[反向传播]
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/111592279&quot;&gt;今天聊聊PID - zzzSid的文章 - 知乎&lt;/a&gt;
            &lt;ul&gt;
              &lt;li&gt;目标函数$cost = \frac{1}{2}(position_t-target_t)^2$&lt;/li&gt;
              &lt;li&gt;不过我并不是很赞同他使用动态参数的做法&lt;/li&gt;
              &lt;li&gt;目标函数也未考虑收敛速度和周期&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;http://hjhyxb.ijournals.cn/ch/reader/create_pdf.aspx?file_no=20150402&amp;amp;year_id=2015&amp;amp;quarter_id=4&amp;amp;falg=1&quot;&gt;基于支持向量机回归和RBF神经网络的PID整定 - 海军航空工程学院&lt;/a&gt;
            &lt;ul&gt;
              &lt;li&gt;原理跟上面一样&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;理论分析&quot;&gt;理论分析&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Laplace Transform&lt;/strong&gt;[拉普拉斯变换]&lt;/li&gt;
  &lt;li&gt;$L(s) = \int_0^{\infty}f(t)e^{-st}dt$
    &lt;ul&gt;
      &lt;li&gt;其中$s$是个复数&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;为了更好的理解&lt;strong&gt;Laplace Transform&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;回想一下&lt;strong&gt;Fourier transform&lt;/strong&gt;[傅里叶变换]&lt;/li&gt;
  &lt;li&gt;$F(\omega) = \int_{-\infty}^{\infty}f(t)e^{-i\omega t}dt$&lt;/li&gt;
&lt;/ul&gt;</content><author><name>麦丽素</name></author><category term="zhihu" /><summary type="html">PID Contorl</summary></entry><entry><title type="html">Convert Camera Parameters [model of colmap]</title><link href="https://ucas.io/3d/Convert-Camera-Parameters/" rel="alternate" type="text/html" title="Convert Camera Parameters [model of colmap]" /><published>2021-08-13T19:21:12+08:00</published><updated>2021-08-13T19:21:12+08:00</updated><id>https://ucas.io/3d/Convert-Camera-Parameters</id><content type="html" xml:base="https://ucas.io/3d/Convert-Camera-Parameters/">&lt;h2 id=&quot;try-colmap-with-cudagpu&quot;&gt;Try Colmap with cuda(gpu)&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;enable gpu with args &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;--SiftExtraction.use_gpu 1&lt;/code&gt;
    &lt;ul&gt;
      &lt;li&gt;but throw qt error, need x display&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;close QT gui by &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;export QT_QPA_PLATFORM=offscreen&lt;/code&gt;
    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;but throw these error below&lt;/p&gt;

        &lt;div class=&quot;language-console highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;go&quot;&gt;*** Aborted at 1628840833 (unix time) try &quot;date -d @1628840833&quot; if you are using GNU date ***
PC: @     0x7f07a36bbbf8 (unknown)
&lt;/span&gt;&lt;span class=&quot;gp&quot;&gt;*** SIGSEGV (@0xe0) received by PID 19386 (TID 0x7f07b1686900) from PID 224;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;stack trace: &lt;span class=&quot;k&quot;&gt;***&lt;/span&gt;
&lt;span class=&quot;go&quot;&gt;    @     0x7f07b0919980 (unknown)
    @     0x7f07a36bbbf8 (unknown)
    @     0x7f07a36bbff8 (unknown)
    @     0x7f07ae65407f QOpenGLContext::create()
    @     0x5601b94e4b93 (unknown)
    @     0x5601b9391777 (unknown)
    @     0x5601b9396eec (unknown)
    @     0x5601b925b4a7 (unknown)
    @     0x5601b924c863 (unknown)
    @     0x7f07ac9edbf7 __libc_start_main
    @     0x5601b925073a (unknown)
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;wait for &lt;a href=&quot;https://github.com/colmap/colmap/issues/1273&quot;&gt;issue#1273&lt;/a&gt; response&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;convert-camera-parameters-from-opencv-matrix-file-to-other-type&quot;&gt;Convert camera parameters from &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;opencv-matrix&lt;/code&gt; file to other type&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;http://ucas/jupyter/lab/tree/3d/cameras/comera_convert.ipynb&quot;&gt;Jupyter Code&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;attation&quot;&gt;Attation&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;This need &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pip install opencv-python&lt;/code&gt; but &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;conda install&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;For now, the version is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;opencv-python==4.5.3.56&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;code&quot;&gt;Code&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;fs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cv2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;FileStorage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;camera.xml&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cv2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;FILE_STORAGE_READ&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;root&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;root&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;root&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;intrinsic&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;root&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getNode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getNode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;camIntrinsics&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;external&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;root&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getNode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getNode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;camExternals&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;width&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;root&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getNode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getNode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;imageSize&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getNode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Width&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;real&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;height&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;root&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getNode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getNode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;imageSize&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getNode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Width&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;real&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;convert for &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;空三&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://ucas/jupyter/lab/tree/3d/cameras/comera_convert.ipynb&quot;&gt;jupyter lab&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;figure-out-the-camera-model-of-colmap&quot;&gt;Figure out the camera model of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;colmap&lt;/code&gt;&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;Camera model list at &lt;a href=&quot;https://colmap.github.io/cameras.html?highlight=undistortion&quot;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;SIMPLE_PINHOLE, PINHOLE
    &lt;ul&gt;
      &lt;li&gt;The easiest model, means 相机图片没有任何畸变，主要指内参&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;SIMPLE_RADIAL, RADIAL
    &lt;ul&gt;
      &lt;li&gt;默认选择，这个会自动估算图片畸变并计算相机内参&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;OPENCV, FULL_OPENCV
    &lt;ul&gt;
      &lt;li&gt;引申搜索到了&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;google nerfies&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;一个3D拍照应用&lt;/li&gt;
      &lt;li&gt;&lt;img src=&quot;https://raw.githubusercontent.com/FavorMylikes/hackmd-note/img/imgogjbzom3fyingbqavx06.gif&quot; alt=&quot;ogjbzom3fyingbqavx06&quot; /&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://github.com/google/nerfies&quot;&gt;&lt;img src=&quot;https://github-readme-stats.vercel.app/api/pin/?username=google&amp;amp;repo=nerfies&amp;amp;show_owner=true&quot; alt=&quot;Readme Card&quot; /&gt;&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://colab.research.google.com/github/google/nerfies/blob/main/notebooks/Nerfies_Capture_Processing.ipynb&quot;&gt;prepare training data - colab&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://colab.sandbox.google.com/github/google/nerfies/blob/main/notebooks/Nerfies_Training.ipynb&quot;&gt;training data - colab&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;SIMPLE_RADIAL_FISHEYE, RADIAL_FISHEYE, OPENCV_FISHEYE, FOV, THIN_PRISM_FISHEYE
    &lt;ul&gt;
      &lt;li&gt;用于鱼眼镜头&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>麦丽素</name></author><category term="3d" /><summary type="html">Try Colmap with cuda(gpu)</summary></entry><entry><title type="html">Problem Analysis About Texture mapping</title><link href="https://ucas.io/3d/Problem-Analysis-About-Texture-mapping/" rel="alternate" type="text/html" title="Problem Analysis About Texture mapping" /><published>2021-08-12T18:30:21+08:00</published><updated>2021-08-12T18:30:21+08:00</updated><id>https://ucas.io/3d/Problem-Analysis-About-Texture-mapping</id><content type="html" xml:base="https://ucas.io/3d/Problem-Analysis-About-Texture-mapping/">&lt;h2 id=&quot;现象&quot;&gt;现象&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;贴图不完整&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/FavorMylikes/hackmd-note/img/img20210812183559.png&quot; alt=&quot;20210812183559&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;贴图边缘抖动&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/FavorMylikes/hackmd-note/img/imgbandicam-2021-08-12-18-38-00-941.gif&quot; alt=&quot;bandicam-2021-08-12-18-38-00-941&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;原因分析&quot;&gt;原因分析&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;mesh交叉&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/FavorMylikes/hackmd-note/img/img20210812184013.png&quot; alt=&quot;20210812184013&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;平面过薄&lt;/li&gt;
&lt;/ul&gt;</content><author><name>麦丽素</name></author><category term="3d" /><summary type="html">现象</summary></entry><entry><title type="html">ColMap OpenMVS workflow</title><link href="https://ucas.io/3d/ColMap-OpenMVS-workflow/" rel="alternate" type="text/html" title="ColMap OpenMVS workflow" /><published>2021-08-12T16:55:38+08:00</published><updated>2021-08-12T16:55:38+08:00</updated><id>https://ucas.io/3d/ColMap-OpenMVS-workflow</id><content type="html" xml:base="https://ucas.io/3d/ColMap-OpenMVS-workflow/">&lt;h2 id=&quot;through-a-lot-of-reading-about-those-doc-and-issue&quot;&gt;Through a lot of reading about those doc and issue&lt;/h2&gt;

&lt;p&gt;I wanna write a tutorial for fresh people.&lt;/p&gt;

&lt;p&gt;This is prepare for &lt;strong&gt;linux server (means no desktop)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;And I have compile the latest version &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;colmap&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;openmvs&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;step-1&quot;&gt;Step 1&lt;/h3&gt;

&lt;div class=&quot;language-console highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;colmap feature_extractor \
--SiftExtraction.use_gpu 0 \
--database_path $&lt;/span&gt;PROJECT/database.db&lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--image_path&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$DATA_ROOT&lt;/span&gt;/&lt;span class=&quot;nv&quot;&gt;$PROJECT&lt;/span&gt;/images
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;here &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;--SiftExtraction.use_gpu&lt;/code&gt; is using for linux server only, you can comment it out if you have desktop.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;--ImageReader.camera_model PINHOLE&lt;/code&gt;, you could choice other one, check the list &lt;a href=&quot;https://colmap.github.io/cameras.html&quot;&gt;camera model&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;For using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;InterfaceCOLMAP&lt;/code&gt;, you must specify &lt;strong&gt;PINHOLE&lt;/strong&gt; model&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;step-2&quot;&gt;Step 2&lt;/h3&gt;

&lt;div class=&quot;language-console highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;colmap exhaustive_matcher\
--SiftMatching.use_gpu 0\
--database_path $&lt;/span&gt;PROJECT/database.db
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;here &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;--SiftMatching.use_gpu 0&lt;/code&gt;  has same effect with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SiftExtraction.use_gpu&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;step-3&quot;&gt;Step 3&lt;/h3&gt;

&lt;div class=&quot;language-console highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;colmap mapper\
--database_path $&lt;/span&gt;PROJECT/database.db &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--image_path&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$DATA_ROOT&lt;/span&gt;/&lt;span class=&quot;nv&quot;&gt;$PROJECT&lt;/span&gt;/images &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--output_path&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$PROJECT&lt;/span&gt;/sparse 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;step-4&quot;&gt;Step 4&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;去除图片的畸变(undistort)&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-console highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;colmap image_undistorter \
--image_path $&lt;/span&gt;DATA_ROOT/&lt;span class=&quot;nv&quot;&gt;$PROJECT&lt;/span&gt;/images &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--input_path&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$PROJECT&lt;/span&gt;/sparse/0 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--output_path&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$PROJECT&lt;/span&gt;/dense &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--output_type&lt;/span&gt; COLMAP
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;here &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;--output_type&lt;/code&gt;, you could find the usage at &lt;a href=&quot;https://colmap.github.io/cli.html?highlight=undistortion&quot;&gt;colmap&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;把相机内存转化为txt格式方便openmvs读取&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-console highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;colmap model_converter \
--input_path $&lt;/span&gt;PROJECT/dense/sparse &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--output_path&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$PROJECT&lt;/span&gt;/dense/sparse &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--output_type&lt;/span&gt; TXT
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;At this step, you will see three &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;txt&lt;/code&gt; file will be created at &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sparse&lt;/code&gt; dir.
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cameras.txt&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;images.txt&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;point3D.txt&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;And &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PINHOLE&lt;/code&gt; is in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cameras.txt&lt;/code&gt; you will see&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;step-5&quot;&gt;Step 5&lt;/h3&gt;

&lt;div class=&quot;language-console highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;InterfaceCOLMAP \
--working-folder $&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;pwd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;/&lt;span class=&quot;nv&quot;&gt;$PROJECT&lt;/span&gt;/ &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--input-file&lt;/span&gt; &lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;pwd&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;/&lt;span class=&quot;nv&quot;&gt;$PROJECT&lt;/span&gt;/ &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--output-file&lt;/span&gt; &lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;pwd&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;/&lt;span class=&quot;nv&quot;&gt;$PROJECT&lt;/span&gt;/model_colmap.mvs
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;step-6&quot;&gt;Step 6&lt;/h3&gt;

&lt;div class=&quot;language-console highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;DensifyPointCloud \
--input-file $&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;pwd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;/&lt;span class=&quot;nv&quot;&gt;$PROJECT&lt;/span&gt;/model_colmap.mvs &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--working-folder&lt;/span&gt; &lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;pwd&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;/&lt;span class=&quot;nv&quot;&gt;$PROJECT&lt;/span&gt;/ &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--output-file&lt;/span&gt; &lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;pwd&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;/&lt;span class=&quot;nv&quot;&gt;$PROJECT&lt;/span&gt;/model_dense.mvs &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--archive-type&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-1&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Here &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;--archive-type -1&lt;/code&gt; must be set&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;step-7&quot;&gt;Step 7&lt;/h3&gt;

&lt;div class=&quot;language-console highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;ReconstructMesh --input-file $&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;pwd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;/&lt;span class=&quot;nv&quot;&gt;$PROJECT&lt;/span&gt;/model_dense.mvs &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--working-folder&lt;/span&gt; &lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;pwd&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;/&lt;span class=&quot;nv&quot;&gt;$PROJECT&lt;/span&gt;/ &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--output-file&lt;/span&gt; &lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;pwd&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;/&lt;span class=&quot;nv&quot;&gt;$PROJECT&lt;/span&gt;/model_dense_mesh.mvs
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;step-8&quot;&gt;Step 8&lt;/h3&gt;

&lt;div class=&quot;language-console highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;RefineMesh \
--resolution-level 1 \
--input-file $&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;pwd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;/&lt;span class=&quot;nv&quot;&gt;$PROJECT&lt;/span&gt;/model_dense_mesh.mvs &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--working-folder&lt;/span&gt; &lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;pwd&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;/&lt;span class=&quot;nv&quot;&gt;$PROJECT&lt;/span&gt;/ &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--output-file&lt;/span&gt; &lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;pwd&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;/&lt;span class=&quot;nv&quot;&gt;$PROJECT&lt;/span&gt;/model_dense_mesh_refine.mvs
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;step-9&quot;&gt;Step 9&lt;/h3&gt;

&lt;div class=&quot;language-console highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;TextureMesh \
--export-type obj \
--output-file $&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;pwd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;/&lt;span class=&quot;nv&quot;&gt;$PROJECT&lt;/span&gt;/model.obj &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--working-folder&lt;/span&gt; &lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;pwd&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;/&lt;span class=&quot;nv&quot;&gt;$PROJECT&lt;/span&gt;/ &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--input-file&lt;/span&gt; &lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;pwd&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;/&lt;span class=&quot;nv&quot;&gt;$PROJECT&lt;/span&gt;/model_dense_mesh_refine.mvs
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;final&quot;&gt;FINAL&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;You will get &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;model.mtl&lt;/code&gt; &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;model.obj&lt;/code&gt; and the texure &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;model_material_0_map_Kd.jpg&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Open obj with software you like, I’ll recommend &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;MAYA&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;code&quot;&gt;Code&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://ucas/jupyter/lab/tree/3d/colmap_script.ipynb&quot;&gt;ucas script - ipynb&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>麦丽素</name></author><category term="3d" /><summary type="html">Through a lot of reading about those doc and issue</summary></entry><entry><title type="html">Make OpenMVS work at jupyter</title><link href="https://ucas.io/3d/Make-OpenMVS-Work-at-Jupyter/" rel="alternate" type="text/html" title="Make OpenMVS work at jupyter" /><published>2021-08-11T18:04:44+08:00</published><updated>2021-08-11T18:04:44+08:00</updated><id>https://ucas.io/3d/Make-OpenMVS-Work-at-Jupyter</id><content type="html" xml:base="https://ucas.io/3d/Make-OpenMVS-Work-at-Jupyter/">&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/FavorMylikes/hackmd-note/img/img20210811172921.png&quot; alt=&quot;20210811172921&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;尝试高清colmap逻辑&quot;&gt;尝试高清ColMap逻辑&lt;/h2&gt;

&lt;h3 id=&quot;feature-extractor-特征点提取&quot;&gt;Feature Extractor 特征点提取&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;--SiftExtraction.use_gpu 0&lt;/code&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;You cannot use the feature extractor in GPU mode without an attached display&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://github.com/colmap/colmap/issues/45#issuecomment-266373096&quot;&gt;issue&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;--ImageReader.camera_model SIMPLE_RADIAL&lt;/code&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://colmap.github.io/cameras.html&quot;&gt;camera model&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;Default is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SIMPLE_RADIAL&lt;/code&gt;, you can choice one of
        &lt;ul&gt;
          &lt;li&gt;PINHOLE&lt;/li&gt;
          &lt;li&gt;RADIAL&lt;/li&gt;
          &lt;li&gt;OPENCV&lt;/li&gt;
          &lt;li&gt;SIMPLE_RADIAL_FISHEYE&lt;/li&gt;
          &lt;li&gt;RADIAL_FISHEYE&lt;/li&gt;
          &lt;li&gt;OPENCV_FISHEYE&lt;/li&gt;
          &lt;li&gt;FOV&lt;/li&gt;
          &lt;li&gt;THIN_PRISM_FISHEYE&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-console highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;colmap feature_extractor \
   --database_path $&lt;/span&gt;DATASET_PATH/database.db &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;--image_path&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$DATASET_PATH&lt;/span&gt;/images&lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
   &lt;span class=&quot;nt&quot;&gt;--SiftExtraction&lt;/span&gt;.use_gpu 0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;特征匹配&quot;&gt;特征匹配&lt;/h2&gt;

&lt;div class=&quot;language-console highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;go&quot;&gt;colmap exhaustive_matcher\
--database_path database.db
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;mapper&quot;&gt;Mapper&lt;/h2&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;mkdir &lt;/span&gt;sparse
colmap mapper&lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--database_path&lt;/span&gt; database.db &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--image_path&lt;/span&gt; /opt/OpenSfM/data/dinosaur/images &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--output_path&lt;/span&gt; ./sparse
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;model-coverter&quot;&gt;Model Coverter&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;the out put type could be one of &lt;strong&gt;{BIN, TXT, NVM, Bundler, VRML, PLY, R3D, CAM}&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;colmap model_converter &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--input_path&lt;/span&gt; sparse/0 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--output_path&lt;/span&gt; model.nvm &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--output_type&lt;/span&gt; NVM
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;convert-to-mvs-file&quot;&gt;Convert to mvs file&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;InterfaceCOLMAP
    &lt;ul&gt;
      &lt;li&gt;need &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cameras.txt&lt;/code&gt; and so on at sparse with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PINHOLD&lt;/code&gt; camera mode&lt;/li&gt;
      &lt;li&gt;you can set it by &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;colmap model_converter --output_type&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;InterfaceCOLMAP &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--input-file&lt;/span&gt; &lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;pwd&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;/&lt;span class=&quot;nv&quot;&gt;$PROJECT&lt;/span&gt;/ &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--image-folder&lt;/span&gt; &lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;pwd&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;/&lt;span class=&quot;nv&quot;&gt;$PROJECT&lt;/span&gt;/undistorted_images &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--output-file&lt;/span&gt; &lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;pwd&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;/&lt;span class=&quot;nv&quot;&gt;$PROJECT&lt;/span&gt;/model_colmap.mvs
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;InterfaceCOLMAP&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;InterfaceCOLMAP &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--input-file&lt;/span&gt; &lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;pwd&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;/&lt;span class=&quot;nv&quot;&gt;$PROJECT&lt;/span&gt;/ &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--image-folder&lt;/span&gt; &lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;pwd&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;/&lt;span class=&quot;nv&quot;&gt;$PROJECT&lt;/span&gt;/undistorted_images &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;--output-file&lt;/span&gt; &lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;pwd&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;/&lt;span class=&quot;nv&quot;&gt;$PROJECT&lt;/span&gt;/model_colmap.mvs
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>麦丽素</name></author><category term="3d" /><summary type="html"></summary></entry><entry><title type="html">Robotics Motion Planning week3 and week4</title><link href="https://ucas.io/coursera/Robotics-Motion-Planning-week3-and-week4/" rel="alternate" type="text/html" title="Robotics Motion Planning week3 and week4" /><published>2021-08-11T12:42:35+08:00</published><updated>2021-08-11T12:42:35+08:00</updated><id>https://ucas.io/coursera/Robotics-Motion-Planning-week3-and-week4</id><content type="html" xml:base="https://ucas.io/coursera/Robotics-Motion-Planning-week3-and-week4/">&lt;h2 id=&quot;week3&quot;&gt;week3&lt;/h2&gt;

&lt;h3 id=&quot;probilalitic-road-mapprm&quot;&gt;Probilalitic Road Map(PRM)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/FavorMylikes/hackmd-note/img/img20210811125716.png&quot; alt=&quot;20210811125716&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;rapidy-exploring-random-treerrt-method&quot;&gt;Rapidy Exploring Random Tree(RRT) Method&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/FavorMylikes/hackmd-note/img/img20210811124952.png&quot; alt=&quot;20210811124952&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;rrt-2&quot;&gt;RRT 2&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/FavorMylikes/hackmd-note/img/img20210811125331.png&quot; alt=&quot;20210811125331&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;week4&quot;&gt;Week4&lt;/h2&gt;

&lt;h3 id=&quot;artificial-potential-field人造势场&quot;&gt;Artificial Potential Field[人造势场]&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/FavorMylikes/hackmd-note/img/img20210811134459.png&quot; alt=&quot;20210811134459&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;规划路径平滑化&lt;/li&gt;
  &lt;li&gt;将随机取点改为梯度下降法&lt;/li&gt;
  &lt;li&gt;Attractive Field[引力场]
    &lt;ul&gt;
      &lt;li&gt;将起点放在高处，终点放在低处&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Repulsive Field[斥力场]
    &lt;ul&gt;
      &lt;li&gt;障碍物提供斥力&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;reference&quot;&gt;Reference&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/144816424&quot;&gt;路径规划-人工势场法(Artificial Potential Field) - 半杯茶的小酒杯的文章 - 知乎&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>麦丽素</name></author><category term="coursera" /><summary type="html">week3</summary></entry><entry><title type="html">Try to use OpenMVS under ubuntu</title><link href="https://ucas.io/coursera/Try-to-use-OpenMVS-under-ubuntu/" rel="alternate" type="text/html" title="Try to use OpenMVS under ubuntu" /><published>2021-08-10T22:37:02+08:00</published><updated>2021-08-10T22:37:02+08:00</updated><id>https://ucas.io/coursera/Try-to-use-OpenMVS-under-ubuntu</id><content type="html" xml:base="https://ucas.io/coursera/Try-to-use-OpenMVS-under-ubuntu/">&lt;h2 id=&quot;run-under-jupyter-lab&quot;&gt;Run under jupyter-lab&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/FavorMylikes/hackmd-note/img/img1628610280(1).jpg&quot; alt=&quot;1628610280(1)&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Open it at &lt;a href=&quot;http://ucas/jupyter/lab/tree/3d/colmap_script.ipynb&quot;&gt;ucas&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;opensfm&quot;&gt;OpenSfM&lt;/h2&gt;

&lt;h3 id=&quot;feature_type&quot;&gt;feature_type&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;KAZE[EECV]風
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://github.com/pablofdezalc/kaze&quot;&gt;github&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://www.robesafe.com/personal/pablo.alcantarilla/kaze.html&quot;&gt;KAZE Features. Pablo F. Alcantarilla, Adrien Bartoli and Andrew J. Davison. In European Conference on Computer Vision (ECCV), Fiorenze, Italy, October 2012. bibtex&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;Perona-Malik方程&lt;/li&gt;
      &lt;li&gt;非线性尺度空间&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;AKAZE[Accelerated-KAZE KAZE的加速版]&lt;/li&gt;
  &lt;li&gt;SIFT
    &lt;ul&gt;
      &lt;li&gt;DoG[Difference of Gaussian]&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;SURF[Speeded up robust features]
    &lt;ul&gt;
      &lt;li&gt;Use Box-Filter[盒子滤波器] instead of DoG&lt;/li&gt;
      &lt;li&gt;Change the size of Box-Filter, to build scala space.&lt;/li&gt;
      &lt;li&gt;方向定位，haar小波&lt;/li&gt;
      &lt;li&gt;Integral image[积分图]
        &lt;ul&gt;
          &lt;li&gt;递归计算&lt;/li&gt;
          &lt;li&gt;
            &lt;div class=&quot;kdmath&quot;&gt;$$
I(x,y)=i(x,y)+I(x-1,y)+I(x,y-1)+I(x-1,y-1)
$$&lt;/div&gt;
          &lt;/li&gt;
          &lt;li&gt;算好之后达到快速计算任意图形区域积分的目的&lt;/li&gt;
          &lt;li&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/e/ee/Prm_VJ_fig3_computeRectangleWithAlpha.png&quot; width=&quot;40%&quot; /&gt;&lt;/li&gt;
          &lt;li&gt;
            &lt;div class=&quot;kdmath&quot;&gt;$$
I_{\square_{ABCD}} = I(C)+I(A)-I(B)-I(D)
$$&lt;/div&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Hessian矩阵&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;HAHOG&lt;/li&gt;
  &lt;li&gt;ORB&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;reference&quot;&gt;Reference&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;SURF is faster than SIFT?
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://stackoverflow.com/a/27398168/5587080&quot;&gt;stackoverflow&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;The Difference between of SIFT and SURF
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.cnblogs.com/gfgwxw/p/9415218.html#&quot;&gt;【CV学习5】SURF算法详解 - 苟富贵&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;KAZE
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://www.shuzhiduo.com/A/RnJWYE1Bdq/&quot;&gt;一点一滴完全突破KAZE特征检测算法，从各向异性扩散滤波开始(1) - 术之多&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/304199431&quot;&gt;Perona-Malik方程（各向同性非线性扩散实现图像滤波） - 查讯纤的文章 - 知乎&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/bluecol/article/details/46690985&quot;&gt;各项异性扩散（Anisotropic diffusion）&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://zh.wikipedia.org/wiki/%E9%9D%9E%E7%AD%89%E5%90%91%E6%80%A7%E6%93%B4%E6%95%A3&quot;&gt;非等向性擴散 - Wikipedia&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>麦丽素</name></author><category term="coursera" /><summary type="html">Run under jupyter-lab</summary></entry><entry><title type="html">Robotics Motion Planning Week 1 and 2</title><link href="https://ucas.io/coursera/Robotics-Motion-Planning-week1-week2/" rel="alternate" type="text/html" title="Robotics Motion Planning Week 1 and 2" /><published>2021-08-10T19:32:03+08:00</published><updated>2021-08-10T19:32:03+08:00</updated><id>https://ucas.io/coursera/Robotics-Motion-Planning-week1-week2</id><content type="html" xml:base="https://ucas.io/coursera/Robotics-Motion-Planning-week1-week2/">&lt;h2 id=&quot;week-1&quot;&gt;Week 1&lt;/h2&gt;

&lt;h3 id=&quot;grassfire-algorithm&quot;&gt;Grassfire Algorithm&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/FavorMylikes/hackmd-note/img/img20210810193416.png&quot; alt=&quot;20210810193416&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;From red point to green point, like fire.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;dijkstras-algorithm地接丝卡尔&quot;&gt;Dijkstra’s Algorithm[地接丝卡尔]&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/5/57/Dijkstra_Animation.gif&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;a-star-algorithma&quot;&gt;A star Algorithm[A*]&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;优先搜索距离终点最近的点&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;week-2&quot;&gt;Week 2&lt;/h2&gt;

&lt;h3 id=&quot;configuration-spacec-space-构型空间&quot;&gt;Configuration Space[C-Space 构型空间]&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;与之相对应的还有 Work-Space&lt;/li&gt;
  &lt;li&gt;对于一个由一个点连接的两段悬臂，他们的旋转角度$\theta_1, $\theta_2$可以表达出悬臂所有能产生的形态&lt;/li&gt;
  &lt;li&gt;即通过$\theta_1,\theta_2$构成的空间表示为悬臂可能的空间&lt;/li&gt;
  &lt;li&gt;通过将笛卡尔体系下的Work-Space转化为C-Space，更方便求解规划问题&lt;/li&gt;
  &lt;li&gt;例如，对于RR arm[2R arm, 二自由度机械臂]&lt;/li&gt;
  &lt;li&gt;&lt;img src=&quot;https://skill-lync-portal.nyc3.digitaloceanspaces.com/tinymce/06_20/15934675311611.jpg&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&quot;https://pic1.zhimg.com/50/v2-284ea537667ae4ccf1db7a46ebd3287d_720w.webp?source=1940ef5c&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;3D 的情形&lt;/li&gt;
  &lt;li&gt;&lt;img src=&quot;https://raw.githubusercontent.com/FavorMylikes/hackmd-note/img/imgbandicam-2021-08-10-20-27-00-953.gif&quot; alt=&quot;bandicam-2021-08-10-20-27-00-953&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;reference&quot;&gt;Reference&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.zhihu.com/question/60108896/answer/224251293&quot;&gt;机器人运动规划中的C space怎样理解？为什么不直接在笛卡尔坐标系下运算呢？ - fly qq的回答 - 知乎&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;visibility-graph&quot;&gt;Visibility Graph&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;将多边形的顶点转化为路径点，转化为路径规划问题&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;img src=&quot;https://raw.githubusercontent.com/FavorMylikes/hackmd-note/img/img20210810204246.png&quot; alt=&quot;20210810204246&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;但是边缘行走很危险&lt;/li&gt;
  &lt;li&gt;另一种方案是，根据多边形的顶点在X轴上将其分割为多个三角形或者梯形，在这些多边形内的直线运动是无障碍的，相应的，做出一个辅助路线图，连接两个可达的三角形或梯形的内部点，再进行路径规划&lt;/li&gt;
  &lt;li&gt;&lt;img src=&quot;https://raw.githubusercontent.com/FavorMylikes/hackmd-note/img/img20210810204813.png&quot; alt=&quot;20210810204813&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;Piano Mover’s Problem&lt;/li&gt;
&lt;/ul&gt;</content><author><name>麦丽素</name></author><category term="coursera" /><summary type="html">Week 1</summary></entry></feed>