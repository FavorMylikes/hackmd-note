<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.24.0 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Texture Paper Reading-[Let There Be Color!] / Notes B</title>
<meta name="description" content="Let There Be Color! - Large-Scale Texturing of 3D Reconstructions                   Paper.pdf                           In this paper we therefore present the first unified texturing approach that handles large, realistic datasets reconstructed from images with a structure-from-motion plus multi-view stereo pipeline.                                           millions of triangles within less than two hours.                       Related                    view selection                            blend multiple views per face[5,13]               one view per face[9,10,15,23]               one view per texel[19]               one view per face but blend close to texture patch borders[2,6]               single view per face based on a pairwise Markov random field[15]                                    smoothness term models                                               view blend                                    weight blending[5]                                            masks indicating                       angle to weight                                                                           suggest the use of vertex colors in combination with mesh subdivision                                                                                                           blending in frequency space[2,6]                                               blend pixels based on angle and proximity to the model[13]               view-dependent texturing— Lumigraph[4]                                   Color Adjustment                                           local                                    seam&#39;s mean[23]                                            heat diffusion                                                                                       global                                    globally optimal luminance correction terms[15]                                                                                                After adjustment luminance differences at seams should be small and the derivative of adjustments within a texture patch should be small                                                                                                                                                                       Assumptions and Base Method                    Pairwise Markov random field energy formulation[15]                        $$ \begin{aligned}       E(l)&amp;=\sum_{F_i\in Faces}E_{data}(F_i, l_i)+\sum_{F_i\in Faces}E_{smooth}(F_i, F_j, l_i, l_j)&amp;(1)   \end{aligned} $$                            $l$: labeling of views               $F$: mesh face               $E_{data}$: good views for texturing a face                                                                                base method: the angle between viewing direction and face normal.                                                                                                       project a face into a view and use the projection’s size as data term[2]                                                                                                       Lumigraph’s view blending weights face normal[4] 💩                                                                                                       the gradient magnitude of the image integrated over the face’s projection[9]                                                                 to solve close-up the faces closest to the camera  that not be in focus and lead to a blurry texture.                       $x,y \pm64pixel$                                                                                       $E_{smooth}$: minimizes seam (i.e., edges between faces textured with differentimages) visibility.               $E(l)$minimized with graph cuts and alpha expansion[3]                                   This Paper [Compute seam color]                                                                We found, that computation of the seam error integrals is a computational bottleneck and cannot be precomputed due to the prohibitively large number of combinations. Furthermore, it favors distant or low-resolution views since a blurry texture produces smaller seam errors, an issue that does not occur in their datasets.                                               Add a additive correction $g$                                $$ \begin{aligned}         &amp;\underset{\mathbf{g}}{\argmin}\sum_v \big(f_{v_{left}} + g_{v_{left}} - (f_{v_{right}}+g_{v_{right}})\big)^2 + \frac{1}{\lambda}\sum_{v_i,v_j}(g_{v_i}-g_{v_j})^2&amp;(2)     \end{aligned} $$                                    $v$: vexel                   $v_{left}$: vexel at left of seam                   $v_{right}$: vexel at left of seam                   $v_i,v_j$: vexel at same seam and adjacent                   $f_{v*}$: color of vexel                   $g$: additive correction                                                                                   After fnding optimal gv for all vertices the corrections for each texel are interpolated from the $g_v$ of its surrounding vertices using barycentric coordinates.                                                                               Large-Scale Texturing Approach                    Preprocessing                            check face visibility by ColNet[11]               precompute the data terms for Equation $(1)$                                   View Selection                            graph cuts and alpha expansion[3]               replace[9] the Data term to                                    $E_{data} = -\int_{\phi(F_i,l_i)}\Vert\nabla(I_{l_i}(p))\Vert_2dp$💩                                            $F_i$: face                       $\phi(F_i,l_i)$: $F_i$’s projection                       $I_{l_i}$: Sobel operator                       $\Vert\nabla(I_{l_i})\Vert_2$: gradient magnitude                       大概意思就是，面投影到图片，计算投影区的Sobel operator, 如果投影区太小没有像素，就gradient magnitude at the projection&#39;s centroid and multiply it with the projection area., 最后把它们加一块                                                                                       Photo-Consistency Check [检查遮挡和行人]                                                                                introduce an additional step to ensure photo-consistency of the texture.                                                           assuming                                                                                                the majority of views see the correct color.                                                                                                                           A minority may see wrong colors                                                                                                           reject inconsistent views                                            mean[19]                       median[13]                       mean-shift algorithm[this]                                                    Compute the face projection’s mean color $c_i$ for each view $i$ in which the face is visible.                           Declare all views seeing the face as inliers.                           Compute mean $\mu$ and covariance matrix $\Sigma$ of all inliers’ mean color $c_i$.                           Evaluate a multi-variate Gaussian function $exp(-\frac{1}{2}(c_i-\mu)^T\Sigma^{-1}(c_i-\mu))$ each view in which the face is visible.                           Clear the inlier list and insert all views whose function value is above a threshold $6E-3$ as default                           Repeat 3.-5. for 10 iterations or until all entries of $\Sigma$ drop below $10E-5$, the inversion of $\Sigma$ becomes unstable, or the number of inliers drops below 4                                                                                                                                       replace the Smoothness Term                                    based on the Potts model                   $E_{smooth} = [l_i\neq l_j]$💩                                            $[\cdot]$: is the Iverson bracket, 满足条件就是1，不满足就是0.                                                                                                           Color Adjustment                            local adjustment with Poisson editing[16]                                    global adjustment[15] problem                                                               the vertex v’s projection into the two images adjacent to the seam. If there are even small registration errors (which there always are), both projections do not correspond to exactly the same spot on the real object. Also, if both images have a different scale the looked up pixels span a different footprint in 3D. This may be irrelevant in controlled lab datasets, but in realistic multi-view stereo datasets the lookups from effectively different points or footprints mislead the global adjustment and produce artifacts.                                                                                       Color Lookup Support Region                                                       $v_1$点的颜色等于两条边的颜色*距离权重                   Equation 2 matrix form                                        $$ \mathbf{\Vert Ag-f\Vert_2^2+\Vert\Gamma g\Vert_2^2=g^T(A^TA+\Gamma^T\Gamma)g-f^TAg+f^Tf} $$                                            $\mathbf{f}$: vector, stacked $f_{v_{left}} - f_{v_{right}}$                       $\mathbf{A}$: sparse matrix with $\pm 1$                       $\mathbf{\Gamma}$: sparse matrix with $\pm 1$                                                           minimize it with conjugate gradient when $\frac{\Vert r\Vert_2}{\Vert\mathbf{A^Tf}\Vert_2}&lt;10^{-5}$                                            $r$: the residual                                                                                                           Poisson Editing                            Have a look at UCAS.IO/Possion-Image-Edit               seams adjustment                                                                                perform local Poisson image editing[9, 16]                                                                                                       Poisson editing of a patch to a 20 pixel wide border strip[this]                                                                                                                                                                                                                              Evaluation                    Data Term and Photo-Consistency Check                                                                              Smoothness Term                                                               Color Adjustment">


  <meta name="author" content="麦丽素">
  
  <meta property="article:author" content="麦丽素">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Notes B">
<meta property="og:title" content="Texture Paper Reading-[Let There Be Color!]">
<meta property="og:url" content="https://ucas.io/3d/Texture-Paper-Reading-Let-There-Be-Color!/">


  <meta property="og:description" content="Let There Be Color! - Large-Scale Texturing of 3D Reconstructions                   Paper.pdf                           In this paper we therefore present the first unified texturing approach that handles large, realistic datasets reconstructed from images with a structure-from-motion plus multi-view stereo pipeline.                                           millions of triangles within less than two hours.                       Related                    view selection                            blend multiple views per face[5,13]               one view per face[9,10,15,23]               one view per texel[19]               one view per face but blend close to texture patch borders[2,6]               single view per face based on a pairwise Markov random field[15]                                    smoothness term models                                               view blend                                    weight blending[5]                                            masks indicating                       angle to weight                                                                           suggest the use of vertex colors in combination with mesh subdivision                                                                                                           blending in frequency space[2,6]                                               blend pixels based on angle and proximity to the model[13]               view-dependent texturing— Lumigraph[4]                                   Color Adjustment                                           local                                    seam&#39;s mean[23]                                            heat diffusion                                                                                       global                                    globally optimal luminance correction terms[15]                                                                                                After adjustment luminance differences at seams should be small and the derivative of adjustments within a texture patch should be small                                                                                                                                                                       Assumptions and Base Method                    Pairwise Markov random field energy formulation[15]                        $$ \begin{aligned}       E(l)&amp;=\sum_{F_i\in Faces}E_{data}(F_i, l_i)+\sum_{F_i\in Faces}E_{smooth}(F_i, F_j, l_i, l_j)&amp;(1)   \end{aligned} $$                            $l$: labeling of views               $F$: mesh face               $E_{data}$: good views for texturing a face                                                                                base method: the angle between viewing direction and face normal.                                                                                                       project a face into a view and use the projection’s size as data term[2]                                                                                                       Lumigraph’s view blending weights face normal[4] 💩                                                                                                       the gradient magnitude of the image integrated over the face’s projection[9]                                                                 to solve close-up the faces closest to the camera  that not be in focus and lead to a blurry texture.                       $x,y \pm64pixel$                                                                                       $E_{smooth}$: minimizes seam (i.e., edges between faces textured with differentimages) visibility.               $E(l)$minimized with graph cuts and alpha expansion[3]                                   This Paper [Compute seam color]                                                                We found, that computation of the seam error integrals is a computational bottleneck and cannot be precomputed due to the prohibitively large number of combinations. Furthermore, it favors distant or low-resolution views since a blurry texture produces smaller seam errors, an issue that does not occur in their datasets.                                               Add a additive correction $g$                                $$ \begin{aligned}         &amp;\underset{\mathbf{g}}{\argmin}\sum_v \big(f_{v_{left}} + g_{v_{left}} - (f_{v_{right}}+g_{v_{right}})\big)^2 + \frac{1}{\lambda}\sum_{v_i,v_j}(g_{v_i}-g_{v_j})^2&amp;(2)     \end{aligned} $$                                    $v$: vexel                   $v_{left}$: vexel at left of seam                   $v_{right}$: vexel at left of seam                   $v_i,v_j$: vexel at same seam and adjacent                   $f_{v*}$: color of vexel                   $g$: additive correction                                                                                   After fnding optimal gv for all vertices the corrections for each texel are interpolated from the $g_v$ of its surrounding vertices using barycentric coordinates.                                                                               Large-Scale Texturing Approach                    Preprocessing                            check face visibility by ColNet[11]               precompute the data terms for Equation $(1)$                                   View Selection                            graph cuts and alpha expansion[3]               replace[9] the Data term to                                    $E_{data} = -\int_{\phi(F_i,l_i)}\Vert\nabla(I_{l_i}(p))\Vert_2dp$💩                                            $F_i$: face                       $\phi(F_i,l_i)$: $F_i$’s projection                       $I_{l_i}$: Sobel operator                       $\Vert\nabla(I_{l_i})\Vert_2$: gradient magnitude                       大概意思就是，面投影到图片，计算投影区的Sobel operator, 如果投影区太小没有像素，就gradient magnitude at the projection&#39;s centroid and multiply it with the projection area., 最后把它们加一块                                                                                       Photo-Consistency Check [检查遮挡和行人]                                                                                introduce an additional step to ensure photo-consistency of the texture.                                                           assuming                                                                                                the majority of views see the correct color.                                                                                                                           A minority may see wrong colors                                                                                                           reject inconsistent views                                            mean[19]                       median[13]                       mean-shift algorithm[this]                                                    Compute the face projection’s mean color $c_i$ for each view $i$ in which the face is visible.                           Declare all views seeing the face as inliers.                           Compute mean $\mu$ and covariance matrix $\Sigma$ of all inliers’ mean color $c_i$.                           Evaluate a multi-variate Gaussian function $exp(-\frac{1}{2}(c_i-\mu)^T\Sigma^{-1}(c_i-\mu))$ each view in which the face is visible.                           Clear the inlier list and insert all views whose function value is above a threshold $6E-3$ as default                           Repeat 3.-5. for 10 iterations or until all entries of $\Sigma$ drop below $10E-5$, the inversion of $\Sigma$ becomes unstable, or the number of inliers drops below 4                                                                                                                                       replace the Smoothness Term                                    based on the Potts model                   $E_{smooth} = [l_i\neq l_j]$💩                                            $[\cdot]$: is the Iverson bracket, 满足条件就是1，不满足就是0.                                                                                                           Color Adjustment                            local adjustment with Poisson editing[16]                                    global adjustment[15] problem                                                               the vertex v’s projection into the two images adjacent to the seam. If there are even small registration errors (which there always are), both projections do not correspond to exactly the same spot on the real object. Also, if both images have a different scale the looked up pixels span a different footprint in 3D. This may be irrelevant in controlled lab datasets, but in realistic multi-view stereo datasets the lookups from effectively different points or footprints mislead the global adjustment and produce artifacts.                                                                                       Color Lookup Support Region                                                       $v_1$点的颜色等于两条边的颜色*距离权重                   Equation 2 matrix form                                        $$ \mathbf{\Vert Ag-f\Vert_2^2+\Vert\Gamma g\Vert_2^2=g^T(A^TA+\Gamma^T\Gamma)g-f^TAg+f^Tf} $$                                            $\mathbf{f}$: vector, stacked $f_{v_{left}} - f_{v_{right}}$                       $\mathbf{A}$: sparse matrix with $\pm 1$                       $\mathbf{\Gamma}$: sparse matrix with $\pm 1$                                                           minimize it with conjugate gradient when $\frac{\Vert r\Vert_2}{\Vert\mathbf{A^Tf}\Vert_2}&lt;10^{-5}$                                            $r$: the residual                                                                                                           Poisson Editing                            Have a look at UCAS.IO/Possion-Image-Edit               seams adjustment                                                                                perform local Poisson image editing[9, 16]                                                                                                       Poisson editing of a patch to a 20 pixel wide border strip[this]                                                                                                                                                                                                                              Evaluation                    Data Term and Photo-Consistency Check                                                                              Smoothness Term                                                               Color Adjustment">



  <meta property="og:image" content="https://raw.githubusercontent.com/FavorMylikes/hackmd-note/img/img20210910164754.png">





  <meta property="article:published_time" content="2021-09-09T16:28:42+08:00">






<link rel="canonical" href="https://ucas.io/3d/Texture-Paper-Reading-Let-There-Be-Color!/">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": null,
      "url": "https://ucas.io/"
    
  }
</script>







<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Notes B Feed">


<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css"></noscript>



    <!-- Favicon generate from realfavicongenerator.net-->
<link rel="apple-touch-icon" sizes="180x180" href="/assets/favicon/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/assets/favicon/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/assets/favicon/favicon-16x16.png">
<link rel="manifest" href="/assets/favicon/site.webmanifest">
<link rel="mask-icon" href="/assets/favicon/safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" content="#ff0000">

  <!--KaTeX-->
  <link
    rel="stylesheet"
    href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css"
    integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X"
    crossorigin="anonymous"
  />
  <script
    defer
    src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js"
    integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4"
    crossorigin="anonymous"
  ></script>
  <script
    defer
    src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js"
    integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa"
    crossorigin="anonymous"
  ></script>
  <script>
    document.addEventListener("DOMContentLoaded", function () {
      renderMathInElement(document.body, {
        delimiters: [
          { left: "$$", right: "$$", display: true },
          { left: "$", right: "$", display: false },
        ],
      });
    });
  </script>

  </head>

  <body class="layout--single">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
          <a class="site-logo" href="/"><img src="https://raw.githubusercontent.com/FavorMylikes/hackmd-note/img/imgucas_logo.png" alt="Notes B"></a>
        
        <a class="site-title" href="/">
          Notes B
          <span class="site-subtitle">麦丽素的日常</span>
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="https://mmistakes.github.io/minimal-mistakes/docs/quick-start-guide/">Quick-Start Guide</a>
            </li><li class="masthead__menu-item">
              <a href="/categories/">Categories</a>
            </li><li class="masthead__menu-item">
              <a href="/tags/">Tags</a>
            </li><li class="masthead__menu-item">
              <a href="/years/">Years</a>
            </li><li class="masthead__menu-item">
              <a href="/months/">Months</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <i class="fas fa-search"></i>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      


  
    



<nav class="breadcrumbs">
  <ol itemscope itemtype="https://schema.org/BreadcrumbList">
    
    
    
      
        <li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
          <a href="https://ucas.io/" itemprop="item"><span itemprop="name">Home</span></a>
          <meta itemprop="position" content="1" />
        </li>
        <span class="sep">/</span>
      
      
        
        <li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
          <a href="/categories/3d" itemprop="item"><span itemprop="name">3d</span></a>
          <meta itemprop="position" content="2" />
        </li>
        <span class="sep">/</span>
      
    
      
      
        <li class="current">Texture Paper Reading-[Let There Be Color!]</li>
      
    
  </ol>
</nav>

  


<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person">

  
    <div class="author__avatar">
      
        <img src="https://www.gravatar.com/avatar/7ac850b26f9a21a153f8f581964e22cd?s=200" alt="麦丽素" itemprop="image">
      
    </div>
  

  <div class="author__content">
    
      <h3 class="author__name" itemprop="name">麦丽素</h3>
    
    
      <div class="author__bio" itemprop="description">
        <p>My life is getting better</p>

      </div>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      

      
        
          
            <li><a href="mailto:l786112323@gmail.com" rel="nofollow noopener noreferrer"><i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i><span class="label">Email</span></a></li>
          
        
          
            <li><a href="https://github.com/FavorMylikes" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i><span class="label">GitHub</span></a></li>
          
        
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Texture Paper Reading-[Let There Be Color!]">
    <meta itemprop="description" content="  Let There Be Color! - Large-Scale Texturing of 3D Reconstructions                Paper.pdf                        In this paper we thereforepresent the first unified texturing approach that handles large, realistic datasets reconstructed from images with a structure-from-motion plus multi-view stereo pipeline.                                      millions of triangles within less than two hours.                    Related                  view selection                          blend multiple views per face[5,13]              one view per face[9,10,15,23]              one view per texel[19]              one view per face but blend close to texture patch borders[2,6]              single view per face based on a pairwise Markov random field[15]                                  smoothness term models                                            view blend                                  weight blending[5]                                          masks indicating                      angle to weight                                                                        suggest the use of vertex colors in combinationwith mesh subdivision                                                                                                      blending in frequency space[2,6]                                            blend pixels based on angle and proximity to the model[13]              view-dependent texturing— Lumigraph[4]                                Color Adjustment                                        local                                  seam&#39;s mean[23]                                          heat diffusion                                                                                  global                                  globally optimal luminance correction terms[15]                                                                                            After adjustment luminance differences at seams should be small and the derivative of adjustments within a texture patch should be small                                                                                                                                                            Assumptions and Base Method                  Pairwise Markov random field energy formulation[15]                      $$\begin{aligned}      E(l)&amp;=\sum_{F_i\in Faces}E_{data}(F_i, l_i)+\sum_{F_i\in Faces}E_{smooth}(F_i, F_j, l_i, l_j)&amp;(1)  \end{aligned}$$                          $l$: labeling of views              $F$: mesh face              $E_{data}$: good views for texturing a face                                                                            base method: the angle between viewing direction and face normal.                                                                                                  project a face into a view and use the projection’s size as data term[2]                                                                                                  Lumigraph’s view blending weights face normal[4] 💩                                                                                                  the gradient magnitude of the image integrated over the face’s projection[9]                                                              to solve close-up the faces closest to the camera  that not be in focus and lead to a blurry texture.                      $x,y \pm64pixel$                                                                                  $E_{smooth}$: minimizes seam (i.e., edges between faces textured with differentimages) visibility.              $E(l)$minimized with graph cuts and alpha expansion[3]                                This Paper [Compute seam color]                                                            We found, that computation of the seam error integrals is a computational bottleneck and cannot be precomputed due to the prohibitively large number of combinations. Furthermore, it favors distant or low-resolution views since a blurry texture produces smaller seam errors, an issue that does not occur in their datasets.                                            Add a additive correction $g$                              $$\begin{aligned}        &amp;\underset{\mathbf{g}}{\argmin}\sum_v \big(f_{v_{left}} + g_{v_{left}} - (f_{v_{right}}+g_{v_{right}})\big)^2 + \frac{1}{\lambda}\sum_{v_i,v_j}(g_{v_i}-g_{v_j})^2&amp;(2)    \end{aligned}$$                                  $v$: vexel                  $v_{left}$: vexel at left of seam                  $v_{right}$: vexel at left of seam                  $v_i,v_j$: vexel at same seam and adjacent                  $f_{v*}$: color of vexel                  $g$: additive correction                                                                              After fnding optimal gv for all vertices the corrections for each texel are interpolated from the $g_v$ of its surrounding vertices using barycentric coordinates.                                                                        Large-Scale Texturing Approach                  Preprocessing                          check face visibility by ColNet[11]              precompute the data terms for Equation $(1)$                                View Selection                          graph cuts and alpha expansion[3]              replace[9] the Data term to                                  $E_{data} = -\int_{\phi(F_i,l_i)}\Vert\nabla(I_{l_i}(p))\Vert_2dp$💩                                          $F_i$: face                      $\phi(F_i,l_i)$: $F_i$’s projection                      $I_{l_i}$: Sobel operator                      $\Vert\nabla(I_{l_i})\Vert_2$: gradient magnitude                      大概意思就是，面投影到图片，计算投影区的Sobel operator, 如果投影区太小没有像素，就gradient magnitude at the projection&#39;s centroid and multiply it with the projection area., 最后把它们加一块                                                                                  Photo-Consistency Check [检查遮挡和行人]                                                                            introduce an additional step to ensure photo-consistency of the texture.                                                        assuming                                                                                            the majority of views see the correct color.                                                                                                                      A minority may see wrong colors                                                                                                      reject inconsistent views                                          mean[19]                      median[13]                      mean-shift algorithm[this]                                                  Compute the face projection’s mean color $c_i$ for each view $i$ in which the face is visible.                          Declare all views seeing the face as inliers.                          Compute mean $\mu$ and covariance matrix $\Sigma$ of all inliers’ mean color $c_i$.                          Evaluate a multi-variate Gaussian function $exp(-\frac{1}{2}(c_i-\mu)^T\Sigma^{-1}(c_i-\mu))$ each view in which the face is visible.                          Clear the inlier list and insert all views whose function value is above a threshold $6E-3$ as default                          Repeat 3.-5. for 10 iterations or until all entries of $\Sigma$ drop below $10E-5$, the inversion of $\Sigma$ becomes unstable, or the number of inliers drops below 4                                                                                                                                replace the Smoothness Term                                  based on the Potts model                  $E_{smooth} = [l_i\neq l_j]$💩                                          $[\cdot]$: is the Iverson bracket, 满足条件就是1，不满足就是0.                                                                                                    Color Adjustment                          local adjustment with Poisson editing[16]                                  global adjustment[15] problem                                                            the vertex v’s projection into the two images adjacent to the seam. If there are even small registration errors (which there always are), both projections do not correspond to exactly the same spot on the real object. Also, if both images have a different scale the looked up pixels span a different footprint in 3D. This may be irrelevant in controlled lab datasets, but in realistic multi-view stereo datasets the lookups from effectively different points or footprints mislead the global adjustment and produce artifacts.                                                                                  Color Lookup Support Region                                                    $v_1$点的颜色等于两条边的颜色*距离权重                  Equation 2 matrix form                                      $$\mathbf{\Vert Ag-f\Vert_2^2+\Vert\Gamma g\Vert_2^2=g^T(A^TA+\Gamma^T\Gamma)g-f^TAg+f^Tf}$$                                          $\mathbf{f}$: vector, stacked $f_{v_{left}} - f_{v_{right}}$                      $\mathbf{A}$: sparse matrix with $\pm 1$                      $\mathbf{\Gamma}$: sparse matrix with $\pm 1$                                                        minimize it with conjugate gradient when $\frac{\Vert r\Vert_2}{\Vert\mathbf{A^Tf}\Vert_2}&lt;10^{-5}$                                          $r$: the residual                                                                                                    Poisson Editing                          Have a look at UCAS.IO/Possion-Image-Edit              seams adjustment                                                                            perform local Poisson image editing[9, 16]                                                                                                  Poisson editing of a patch to a 20 pixel wide border strip[this]                                                                                                                                                                                                                Evaluation                  Data Term and Photo-Consistency Check                                                                        Smoothness Term                                                          Color Adjustment                                                                                  ">
    <meta itemprop="datePublished" content="2021-09-09T16:28:42+08:00">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">Texture Paper Reading-[Let There Be Color!]
</h1>
          

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2021-09-09T16:28:42+08:00">September 9, 2021</time>
      </span>
    

    <span class="page__meta-sep"></span>

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          3 minute read
        
      </span>
    
  </p>


        </header>
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right ">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On this page</h4></header>
              <ul class="toc__menu"><li><a href="#reference">Reference</a></li></ul>

            </nav>
          </aside>
        
        <ul>
  <li><a href="https://link.springer.com/chapter/10.1007/978-3-319-10602-1_54">Let There Be Color! - Large-Scale Texturing of 3D Reconstructions</a>
    <ul>
      <li><img src="https://img.shields.io/badge/eccv-2014-blue?style=flat-square" alt="j" /><img src="https://img.shields.io/badge/cite-229-blue?style=flat-square" alt="cite" /></li>
      <li><a href="https://www.gcc.tu-darmstadt.de/media/gcc/papers/Waechter-2014-LTB.pdf">Paper.pdf</a></li>
      <li>
        <blockquote>
          <p>In this paper we therefore
present the first unified texturing approach that handles large, realistic datasets reconstructed from images with a structure-from-motion plus multi-view stereo pipeline.</p>
        </blockquote>
      </li>
      <li>
        <blockquote>
          <p><strong>millions of triangles</strong> within less <strong>than two hours</strong>.</p>
        </blockquote>
      </li>
      <li>Related
        <ul>
          <li>view selection
            <ul>
              <li>blend multiple views per face[5,13]</li>
              <li>one view per face[9,10,15,23]</li>
              <li>one view per texel[19]</li>
              <li>one view per face but blend close to texture patch borders[2,6]</li>
              <li>single view per face based on a <strong>pairwise Markov random field</strong>[15]
                <ul>
                  <li>smoothness term models</li>
                </ul>
              </li>
              <li>view blend
                <ul>
                  <li>weight blending[5]
                    <ul>
                      <li><strong>masks indicating</strong></li>
                      <li>angle to weight</li>
                      <li>
                        <blockquote>
                          <p>suggest the use of vertex colors in combination
with mesh subdivision</p>
                        </blockquote>
                      </li>
                    </ul>
                  </li>
                  <li>blending in frequency space[2,6]</li>
                </ul>
              </li>
              <li>blend pixels based on angle and proximity to the model[13]</li>
              <li>view-dependent texturing— <strong>Lumigraph</strong>[4]</li>
            </ul>
          </li>
          <li>Color Adjustment
            <ul>
              <li><img src="https://raw.githubusercontent.com/FavorMylikes/hackmd-note/img/img20210909165327.png" alt="20210909165327" /></li>
              <li>local
                <ul>
                  <li><code class="language-plaintext highlighter-rouge">seam's mean</code>[23]
                    <ul>
                      <li>heat diffusion</li>
                    </ul>
                  </li>
                </ul>
              </li>
              <li>global
                <ul>
                  <li>globally optimal luminance correction terms[15]
                    <ul>
                      <li>
                        <blockquote>
                          <p>After adjustment luminance differences at seams should be small and the derivative of adjustments within a texture patch should be small</p>
                        </blockquote>
                      </li>
                    </ul>
                  </li>
                </ul>
              </li>
            </ul>
          </li>
        </ul>
      </li>
      <li>Assumptions and Base Method
        <ul>
          <li>Pairwise Markov random field energy formulation[15]</li>
          <li>
            <div class="kdmath">$$
\begin{aligned}
      E(l)&=\sum_{F_i\in Faces}E_{data}(F_i, l_i)+\sum_{F_i\in Faces}E_{smooth}(F_i, F_j, l_i, l_j)&(1)
  \end{aligned}
$$</div>
            <ul>
              <li>$l$: labeling of views</li>
              <li>$F$: mesh face</li>
              <li>$E_{data}$: <code class="language-plaintext highlighter-rouge">good</code> views for texturing a face
                <ol>
                  <li>
                    <blockquote>
                      <p>base method: the <strong>angle</strong> between viewing direction and face normal.</p>
                    </blockquote>
                  </li>
                  <li>
                    <blockquote>
                      <p>project a face into a view and use the <strong>projection’s size</strong> as data term[2]</p>
                    </blockquote>
                  </li>
                  <li>
                    <blockquote>
                      <p>Lumigraph’s view blending weights face normal[4] 💩</p>
                    </blockquote>
                  </li>
                  <li>
                    <blockquote>
                      <p>the gradient magnitude of the image integrated over the face’s projection[9]</p>
                    </blockquote>
                    <ul>
                      <li>to solve <code class="language-plaintext highlighter-rouge">close-up the faces closest to the camera</code>  that <code class="language-plaintext highlighter-rouge">not be in focus</code> and <code class="language-plaintext highlighter-rouge">lead to a blurry texture</code>.</li>
                      <li>$x,y \pm64pixel$</li>
                    </ul>
                  </li>
                </ol>
              </li>
              <li>$E_{smooth}$: minimizes seam (i.e., edges between faces textured with differentimages) visibility.</li>
              <li>$E(l)$minimized with graph cuts and alpha expansion[3]</li>
            </ul>
          </li>
          <li>This Paper [Compute seam color]
            <ul>
              <li>
                <blockquote>
                  <p>We found, that computation of the seam error integrals is a computational bottleneck and cannot be precomputed due to the prohibitively large number of combinations. Furthermore, it favors distant or low-resolution views since a blurry texture produces smaller seam errors, an issue that does not occur in their datasets.</p>
                </blockquote>
              </li>
              <li>Add a <code class="language-plaintext highlighter-rouge">additive correction</code> $g$</li>
              <li>
                <div class="kdmath">$$
\begin{aligned}
        &\underset{\mathbf{g}}{\argmin}\sum_v \big(f_{v_{left}} + g_{v_{left}} - (f_{v_{right}}+g_{v_{right}})\big)^2 + \frac{1}{\lambda}\sum_{v_i,v_j}(g_{v_i}-g_{v_j})^2&(2)
    \end{aligned}
$$</div>
                <ul>
                  <li>$v$: vexel</li>
                  <li>$v_{left}$: vexel at left of seam</li>
                  <li>$v_{right}$: vexel at left of seam</li>
                  <li>$v_i,v_j$: vexel at same seam and <strong><code class="language-plaintext highlighter-rouge">adjacent</code></strong></li>
                  <li>$f_{v*}$: color of vexel</li>
                  <li>$g$: additive correction</li>
                </ul>
              </li>
              <li>
                <blockquote>
                  <p>After fnding optimal gv for all vertices the corrections for each texel are <strong>interpolated</strong> from the $g_v$ of its surrounding vertices using <strong>barycentric coordinates</strong>.</p>
                </blockquote>
              </li>
            </ul>
          </li>
        </ul>
      </li>
      <li>Large-Scale Texturing Approach
        <ul>
          <li>Preprocessing
            <ul>
              <li>check <code class="language-plaintext highlighter-rouge">face visibility</code> by <code class="language-plaintext highlighter-rouge">ColNet</code>[11]</li>
              <li>precompute the data terms for Equation $(1)$</li>
            </ul>
          </li>
          <li>View Selection
            <ul>
              <li>graph cuts and alpha expansion[3]</li>
              <li>replace[9] the <code class="language-plaintext highlighter-rouge">Data term</code> to
                <ul>
                  <li>$E_{data} = -\int_{\phi(F_i,l_i)}\Vert\nabla(I_{l_i}(p))\Vert_2dp$💩
                    <ul>
                      <li>$F_i$: face</li>
                      <li>$\phi(F_i,l_i)$: $F_i$’s projection</li>
                      <li>$I_{l_i}$: Sobel operator</li>
                      <li>$\Vert\nabla(I_{l_i})\Vert_2$: gradient magnitude</li>
                      <li>大概意思就是，面投影到图片，计算投影区的<code class="language-plaintext highlighter-rouge">Sobel operator</code>, 如果投影区太小没有像素，就<code class="language-plaintext highlighter-rouge">gradient magnitude at the projection's centroid and multiply it with the projection area.</code>, 最后把它们加一块</li>
                    </ul>
                  </li>
                </ul>
              </li>
              <li>Photo-Consistency Check [检查遮挡和行人]
                <ul>
                  <li>
                    <blockquote>
                      <p>introduce an additional step to ensure photo-consistency of the texture.</p>
                    </blockquote>
                  </li>
                  <li>assuming
                    <ul>
                      <li>
                        <blockquote>
                          <p>the majority of views see the correct color.</p>
                        </blockquote>
                      </li>
                      <li>
                        <blockquote>
                          <p>A minority may see wrong colors</p>
                        </blockquote>
                      </li>
                    </ul>
                  </li>
                  <li>reject inconsistent views
                    <ul>
                      <li>mean[19]</li>
                      <li>median[13]</li>
                      <li>mean-shift algorithm[this]
                        <ol>
                          <li>Compute the face projection’s mean color $c_i$ for each view $i$ in which the face is visible.</li>
                          <li>Declare all views seeing the face as inliers.</li>
                          <li>Compute mean $\mu$ and covariance matrix $\Sigma$ of all inliers’ mean color $c_i$.</li>
                          <li>Evaluate a multi-variate Gaussian function $exp(-\frac{1}{2}(c_i-\mu)^T\Sigma^{-1}(c_i-\mu))$ each view in which the face is visible.</li>
                          <li>Clear the inlier list and insert all views whose function value is above a threshold $6E-3$ as default</li>
                          <li>Repeat 3.-5. for <code class="language-plaintext highlighter-rouge">10</code> iterations or until all entries of $\Sigma$ drop below $10E-5$, the inversion of $\Sigma$ becomes unstable, or the number of inliers drops below 4</li>
                        </ol>
                      </li>
                    </ul>
                  </li>
                </ul>
              </li>
              <li>replace the <code class="language-plaintext highlighter-rouge">Smoothness Term</code>
                <ul>
                  <li>based on the <code class="language-plaintext highlighter-rouge">Potts</code> model</li>
                  <li>$E_{smooth} = [l_i\neq l_j]$💩
                    <ul>
                      <li>$[\cdot]$: is the <code class="language-plaintext highlighter-rouge">Iverson bracket</code>, 满足条件就是1，不满足就是0.</li>
                    </ul>
                  </li>
                </ul>
              </li>
            </ul>
          </li>
          <li>Color Adjustment
            <ul>
              <li>local adjustment with Poisson editing[16]
                <ul>
                  <li>global adjustment[15] problem</li>
                  <li>
                    <blockquote>
                      <p>the vertex v’s projection into the two images adjacent to the seam. If there are even <strong>small registration errors</strong> (which there always are), <strong>both projections do not correspond to exactly the same spot on the real object</strong>. Also, if both images have a <strong>different scale</strong> the looked up pixels span a different footprint in 3D. This may be <strong>irrelevant in controlled lab</strong> datasets, but in realistic multi-view stereo datasets the lookups from effectively different points or footprints mislead the <strong>global adjustment</strong> and <strong>produce artifacts</strong>.</p>
                    </blockquote>
                  </li>
                </ul>
              </li>
              <li>Color Lookup Support Region
                <ul>
                  <li><img src="https://raw.githubusercontent.com/FavorMylikes/hackmd-note/img/img20210910011941.png" alt="20210910011941" /></li>
                  <li>$v_1$点的颜色等于两条边的颜色*距离权重</li>
                  <li><strong>Equation 2 matrix form</strong></li>
                  <li>
                    <div class="kdmath">$$
\mathbf{\Vert Ag-f\Vert_2^2+\Vert\Gamma g\Vert_2^2=g^T(A^TA+\Gamma^T\Gamma)g-f^TAg+f^Tf}
$$</div>
                    <ul>
                      <li>$\mathbf{f}$: vector, stacked $f_{v_{left}} - f_{v_{right}}$</li>
                      <li>$\mathbf{A}$: sparse matrix with $\pm 1$</li>
                      <li>$\mathbf{\Gamma}$: sparse matrix with $\pm 1$</li>
                    </ul>
                  </li>
                  <li>minimize it with <code class="language-plaintext highlighter-rouge">conjugate gradient</code> when $\frac{\Vert r\Vert_2}{\Vert\mathbf{A^Tf}\Vert_2}&lt;10^{-5}$
                    <ul>
                      <li>$r$: the residual</li>
                    </ul>
                  </li>
                </ul>
              </li>
            </ul>
          </li>
          <li>Poisson Editing
            <ul>
              <li>Have a look at <a href="https://ucas.io/3d/Possion-Image-Edit/">UCAS.IO/Possion-Image-Edit</a></li>
              <li>seams adjustment
                <ul>
                  <li>
                    <blockquote>
                      <p>perform local Poisson image editing[9, 16]</p>
                    </blockquote>
                  </li>
                  <li>
                    <blockquote>
                      <p>Poisson editing of a patch to a 20 pixel wide border strip[this]</p>
                    </blockquote>
                  </li>
                  <li>
                    <blockquote>
                      <p><img src="https://raw.githubusercontent.com/FavorMylikes/hackmd-note/img/img20210910163143.png" alt="20210910163143" height="100px" /></p>
                    </blockquote>
                  </li>
                </ul>
              </li>
            </ul>
          </li>
        </ul>
      </li>
      <li>Evaluation
        <ul>
          <li>Data Term and Photo-Consistency Check
            <ul>
              <li><img src="https://raw.githubusercontent.com/FavorMylikes/hackmd-note/img/img20210910171331.png" alt="20210910171331" /></li>
              <li><img src="https://raw.githubusercontent.com/FavorMylikes/hackmd-note/img/img20210910171511.png" alt="20210910171511" /></li>
            </ul>
          </li>
          <li>Smoothness Term
            <ul>
              <li><img src="https://raw.githubusercontent.com/FavorMylikes/hackmd-note/img/img20210910171606.png" alt="20210910171606" /></li>
            </ul>
          </li>
          <li>Color Adjustment
            <ul>
              <li><img src="https://raw.githubusercontent.com/FavorMylikes/hackmd-note/img/img20210910172145.png" alt="20210910172145" /></li>
              <li><img src="https://raw.githubusercontent.com/FavorMylikes/hackmd-note/img/img20210910172445.png" alt="20210910172445" /></li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="reference">Reference</h2>

<ol>
  <li><img src="https://img.shields.io/badge/ICCV-2009-blue?style=flat-square" alt="j" /><img src="https://img.shields.io/badge/cite-2240-blue?style=flat-square" alt="cite" /></li>
  <li><img src="https://img.shields.io/badge/ICPR-2008-blue?style=flat-square" alt="j" /><img src="https://img.shields.io/badge/cite-175-blue?style=flat-square" alt="cite" /></li>
  <li><img src="https://img.shields.io/badge/PAMI-2001-blue?style=flat-square" alt="j" /><img src="https://img.shields.io/badge/cite-9679-blue?style=flat-square" alt="cite" /></li>
  <li><img src="https://img.shields.io/badge/SIGGRAPH-2001-blue?style=flat-square" alt="j" /><img src="https://img.shields.io/badge/cite-975-blue?style=flat-square" alt="cite" /></li>
  <li><img src="https://img.shields.io/badge/C&amp;G-2008-blue?style=flat-square" alt="j" /><img src="https://img.shields.io/badge/cite-160-blue?style=flat-square" alt="cite" /></li>
  <li><img src="https://img.shields.io/badge/Book-2012-blue?style=flat-square" alt="j" /><img src="https://img.shields.io/badge/cite-32-blue?style=flat-square" alt="cite" /></li>
  <li><img src="https://img.shields.io/badge/ECCV-2010-blue?style=flat-square" alt="j" /><img src="https://img.shields.io/badge/cite-687-blue?style=flat-square" alt="cite" /></li>
  <li><img src="https://img.shields.io/badge/CVPR-2010-blue?style=flat-square" alt="j" /><img src="https://img.shields.io/badge/cite-891-blue?style=flat-square" alt="cite" /></li>
  <li><img src="https://img.shields.io/badge/CGF-2010-blue?style=flat-square" alt="j" /><img src="https://img.shields.io/badge/cite-151-blue?style=flat-square" alt="cite" /></li>
  <li><img src="https://img.shields.io/badge/C&amp;G-2013-blue?style=flat-square" alt="j" /><img src="https://img.shields.io/badge/cite-31-blue?style=flat-square" alt="cite" /></li>
  <li><img src="https://img.shields.io/badge/software--blue?style=flat-square" alt="j" /><img src="https://img.shields.io/badge/cite--blue?style=flat-square" alt="cite" /></li>
  <li><img src="https://img.shields.io/badge/IJCV-2013-blue?style=flat-square" alt="j" /><img src="https://img.shields.io/badge/cite-61-blue?style=flat-square" alt="cite" /></li>
  <li><img src="https://img.shields.io/badge/3D_ARCH-2007-blue?style=flat-square" alt="j" /><img src="https://img.shields.io/badge/cite-37-blue?style=flat-square" alt="cite" /></li>
  <li><img src="https://img.shields.io/badge/lib-2010-blue?style=flat-square" alt="j" /><img src="https://img.shields.io/badge/cite--blue?style=flat-square" alt="cite" /></li>
  <li><img src="https://img.shields.io/badge/CVPR-2007-blue?style=flat-square" alt="j" /><img src="https://img.shields.io/badge/cite-208-blue?style=flat-square" alt="cite" /></li>
  <li><img src="https://img.shields.io/badge/ToG-2003-blue?style=flat-square" alt="j" /><img src="https://img.shields.io/badge/cite-2985-blue?style=flat-square" alt="cite" /></li>
  <li><img src="https://img.shields.io/badge/CVPR-2006-blue?style=flat-square" alt="j" /><img src="https://img.shields.io/badge/cite-2761-blue?style=flat-square" alt="cite" /></li>
  <li><img src="https://img.shields.io/badge/3DV-2013-blue?style=flat-square" alt="j" /><img src="https://img.shields.io/badge/cite-114-blue?style=flat-square" alt="cite" /></li>
  <li><img src="https://img.shields.io/badge/SIGGRAPH_Asia-2008-blue?style=flat-square" alt="j" /><img src="https://img.shields.io/badge/cite-332-blue?style=flat-square" alt="cite" /></li>
  <li><img src="https://img.shields.io/badge/SIGGRAPH-2006-blue?style=flat-square" alt="j" /><img src="https://img.shields.io/badge/cite-4051-blue?style=flat-square" alt="cite" /></li>
  <li><img src="https://img.shields.io/badge/Book-2002-blue?style=flat-square" alt="j" /><img src="https://img.shields.io/badge/cite-221-blue?style=flat-square" alt="cite" /></li>
  <li><img src="https://img.shields.io/badge/Book-2008-blue?style=flat-square" alt="j" /><img src="https://img.shields.io/badge/cite-23-blue?style=flat-square" alt="cite" /></li>
  <li><img src="https://img.shields.io/badge/TVC-2007-blue?style=flat-square" alt="j" /><img src="https://img.shields.io/badge/cite-40-blue?style=flat-square" alt="cite" /></li>
</ol>

        
      </section>

      <footer class="page__meta">
        
        


  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/3d" class="page__taxonomy-item" rel="tag">3d</a>
    
    </span>
  </p>


        

  <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time datetime="2021-09-09T16:28:42+08:00">September 9, 2021</time></p>


      </footer>

      <section class="page__share">
  

  <a href="https://twitter.com/intent/tweet?text=Texture+Paper+Reading-%5BLet+There+Be+Color%21%5D%20https%3A%2F%2Fucas.io%2F3d%2FTexture-Paper-Reading-Let-There-Be-Color%21%2F" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fucas.io%2F3d%2FTexture-Paper-Reading-Let-There-Be-Color%21%2F" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=https%3A%2F%2Fucas.io%2F3d%2FTexture-Paper-Reading-Let-There-Be-Color%21%2F" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/3d/Texture-for-dog-project/" class="pagination--pager" title="Texture for dog project
">Previous</a>
    
    
      <a href="/3d/Possion-Image-Edit/" class="pagination--pager" title="Possion Image Edit
">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
    <div class="page__related">
      <h4 class="page__related-title">You May Also Enjoy</h4>
      <div class="grid__wrapper">
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="https://raw.githubusercontent.com/FavorMylikes/hackmd-note/img/img20211009132134.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/3d/Nerf/" rel="permalink">Nerf
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2021-10-09T23:16:43+08:00">October 9, 2021</time>
      </span>
    

    <span class="page__meta-sep"></span>

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-fw fa-clock" aria-hidden="true"></i>
        
          less than 1 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">Nerf
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="https://raw.githubusercontent.com/FavorMylikes/hackmd-note/img/img20211009132134.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/3d/Texture-for-invisible-face/" rel="permalink">Texture for invisible
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2021-10-09T11:19:26+08:00">October 9, 2021</time>
      </span>
    

    <span class="page__meta-sep"></span>

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-fw fa-clock" aria-hidden="true"></i>
        
          less than 1 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">Causes of no texture
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="https://raw.githubusercontent.com/FavorMylikes/hackmd-note/img/img20210927162819.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/3d/Cmake-Bug/" rel="permalink">Cmake Bug
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2021-10-08T15:56:23+08:00">October 8, 2021</time>
      </span>
    

    <span class="page__meta-sep"></span>

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-fw fa-clock" aria-hidden="true"></i>
        
          1 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">Cmake can not find OpenMP
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="https://raw.githubusercontent.com/FavorMylikes/hackmd-note/img/img20210927162819.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/3d/Trangle-Rasterization/" rel="permalink">Trangle Rasterization
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2021-09-28T17:08:24+08:00">September 28, 2021</time>
      </span>
    

    <span class="page__meta-sep"></span>

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-fw fa-clock" aria-hidden="true"></i>
        
          less than 1 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">OpenMVS[Homogeneous Coordinate]
</p>
  </article>
</div>

        
      </div>
    </div>
  
  
</div>

    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><div class="search-searchbar"></div>
  <div class="search-hits"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2021 Notes B. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>


<!-- Including InstantSearch.js library and styling -->
<script src="https://cdn.jsdelivr.net/npm/instantsearch.js@2.3.3/dist/instantsearch.min.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.3.3/dist/instantsearch.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.3.3/dist/instantsearch-theme-algolia.min.css">

<script>
// Instanciating InstantSearch.js with Algolia credentials
const search = instantsearch({
  appId: '7UHEFEG9HB',
  apiKey: 'b1cdde9827760050f51383c6c78127bf',
  indexName: 'prod_UCAS_IO',
  searchParameters: {
    restrictSearchableAttributes: [
      'title',
      'content'
    ]
  }
});

const hitTemplate = function(hit) {
  const url = hit.url;
  const hightlight = hit._highlightResult;
  const title = hightlight.title && hightlight.title.value  || "";
  const content = hightlight.html && hightlight.html.value  || "";

  return `
    <div class="list__item">
      <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
        <h2 class="archive__item-title" itemprop="headline"><a href="${url}">${title}</a></h2>
        <div class="archive__item-excerpt" itemprop="description">${content}</div>
      </article>
    </div>
  `;
}

// Adding searchbar and results widgets
search.addWidget(
  instantsearch.widgets.searchBox({
    container: '.search-searchbar',
    poweredBy: true,
    placeholder: 'Enter your search term...'
  })
);
search.addWidget(
  instantsearch.widgets.hits({
    container: '.search-hits',
    templates: {
      item: hitTemplate,
      empty: 'No results',
    }
  })
);

// Starting the search only when toggle is clicked
$(document).ready(function () {
  $(".search__toggle").on("click", function() {
    if(!search.started) {
      search.start();
    }
  });
});
</script>




  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-QN8PZ697F8"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-QN8PZ697F8', { 'anonymize_ip': false});
</script>









  </body>
</html>
